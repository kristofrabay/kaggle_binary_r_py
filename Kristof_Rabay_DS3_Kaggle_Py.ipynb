{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why I used Python (not only R) for the Kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using R to stack a GBM and an RF together with a neural net metalearner in h2o, and trying out Keras and xgBoost separately, I wanted to enhance my stacking model with xgBoost (Windows does not let me in h2o). Meanwhile, I also wanted to see why so many Kagglers use LightGBM for their submissions. After numerous attempts and fails to install LightGBM to R, I decided to turn to Python, re-do the whole assignment from scratch and build an ensemble in skLearn with GBM, LightGBM, xgBoost, RF and possibly a CatBoost, all as base-learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C://Users/Krisz/Desktop/ceu/materials/winter_1/ml/own/ds3_assignments/kaggle_ds3/train.csv\")\n",
    "test = pd.read_csv(\"C://Users/Krisz/Desktop/ceu/materials/winter_1/ml/own/ds3_assignments/kaggle_ds3/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know from the time spent in R which features to drop and which to scale..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['url', ' timedelta', ' n_non_stop_words', ' n_non_stop_unique_tokens', ' kw_avg_min'], axis=1, inplace=True)\n",
    "test.drop(['url', ' timedelta', ' n_non_stop_words', ' n_non_stop_unique_tokens', ' kw_avg_min'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns = lambda x: x.strip(), inplace = True)\n",
    "test.rename(columns = lambda x: x.strip(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['n_tokens_title' , 'n_tokens_content' , 'n_unique_tokens' , 'n_non_stop_words' , 'n_non_stop_unique_tokens' , 'num_hrefs' , 'num_self_hrefs' , 'num_imgs' , 'num_videos' , 'average_token_length' , 'num_keywords' , 'kw_min_min' , 'kw_max_min' , 'kw_avg_min' , 'kw_min_max' , 'kw_max_max' , 'kw_avg_max' , 'kw_min_avg' , 'kw_max_avg' , 'kw_avg_avg' , 'self_reference_min_shares' , 'self_reference_max_shares' , 'self_reference_avg_sharess' , 'LDA_00' , 'LDA_01' , 'LDA_02' , 'LDA_03' , 'LDA_04' , 'global_subjectivity' , 'global_sentiment_polarity' , 'global_rate_positive_words' , 'global_rate_negative_words' , 'rate_positive_words' , 'rate_negative_words' , 'avg_positive_polarity' , 'min_positive_polarity' , 'max_positive_polarity' , 'avg_negative_polarity' , 'min_negative_polarity' , 'max_negative_polarity' , 'title_subjectivity' , 'title_sentiment_polarity' , 'abs_title_subjectivity' , 'abs_title_sentiment_polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.columns.intersection(cols_to_scale)] = scaler.fit_transform(train[train.columns.intersection(cols_to_scale)])\n",
    "test[test.columns.intersection(cols_to_scale)] = scaler.transform(test[test.columns.intersection(cols_to_scale)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['is_popular']\n",
    "X_train = train.drop(['is_popular'], axis=1)\n",
    "X_test = test # no need for .copy() as the two will remain identical, it's just a naming convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train set to an actual train and a validation (serving as test), and the original test will be submitted to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 20202020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below is already tuned, so the 'grid search' isn't actually a grid, it's the final, best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM - awesome tool, easy to use, very powerful even for the first, un-tuned try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LGBMClassifier(application='binary',\n",
       "                                      boosting_type='dart', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      metric='auc', min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=500,\n",
       "                                      n_jobs=-1, num_leaves=31,\n",
       "                                      objective='binary', random_state=20202020,\n",
       "                                      reg_alpha=0.0, reg_lambda=0.0,\n",
       "                                      silent=True, subsample=1.0,\n",
       "                                      subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'drop_rate': [0.15],\n",
       "                         'feature_fraction': [0.6666666666666666],\n",
       "                         'learning_rate': [0.05], 'min_data_in_leaf': [20],\n",
       "                         'num_leaves': [60]},\n",
       "             pre_dispatch='2*n_jobs', refit='AUC', return_train_score=False,\n",
       "             scoring={'AUC': 'roc_auc'}, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = lgbm.LGBMClassifier(boosting_type= 'dart', \n",
    "                                metric = 'auc', \n",
    "                                objective='binary', \n",
    "                                application = 'binary',\n",
    "                                n_estimators = 500, \n",
    "                                random_state = 20202020)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05],\n",
    "    'num_leaves' : [60],\n",
    "    'min_data_in_leaf': [20],   \n",
    "    'feature_fraction': [2/3],     \n",
    "    'drop_rate': [0.15]}\n",
    "\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "\n",
    "lgbm_grid = GridSearchCV(estimator, param_grid, cv = 3, scoring = scoring, refit = 'AUC')\n",
    "\n",
    "lgbm_grid.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7149486615010409"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop_rate': 0.15,\n",
       " 'feature_fraction': 0.6666666666666666,\n",
       " 'learning_rate': 0.05,\n",
       " 'min_data_in_leaf': 20,\n",
       " 'num_leaves': 60}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096274901873657"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = lgbm_grid.best_estimator_.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC: 70.96 best on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_c...\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01], 'max_depth': [9],\n",
       "                         'max_features': [0.6], 'min_samples_leaf': [10],\n",
       "                         'min_samples_split': [2], 'n_estimators': [500],\n",
       "                         'subsample': [0.3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'learning_rate':[0.01], \n",
    "              'n_estimators': [500], \n",
    "              'max_features' : [0.6], \n",
    "              'subsample' : [0.3], \n",
    "              'min_samples_split' : [2],\n",
    "              'max_depth' : [9], \n",
    "              'min_samples_leaf' : [10]}\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state = 20202020)\n",
    "\n",
    "grid_search_gbm = GridSearchCV(estimator = gbm,\n",
    "                               param_grid = param_grid, \n",
    "                               scoring = 'roc_auc',\n",
    "                               n_jobs = -1,\n",
    "                               cv=3, \n",
    "                               verbose = 0)\n",
    "\n",
    "grid_search_gbm.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139866811326913"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 9,\n",
       " 'max_features': 0.6,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 500,\n",
       " 'subsample': 0.3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103703938807249"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = grid_search_gbm.best_estimator_.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC: 71.037 best on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, eval_metric='auc',\n",
       "                                     gamma=None, gpu_id=None,\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constr...\n",
       "                                     random_state=20202020, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=False, verbosity=0),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.45], 'eta': [0.01],\n",
       "                         'gamma': [0], 'max_depth': [7],\n",
       "                         'min_child_weight': [3], 'subsample': [0.75]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'min_child_weight': [3],\n",
    "          'gamma': [0],\n",
    "          'subsample': [0.75],\n",
    "          'colsample_bytree': [0.45],\n",
    "          'max_depth': [7], \n",
    "          'eta' : [0.01]}\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 500, \n",
    "                    objective='binary:logistic',\n",
    "                    verbosity = 0, \n",
    "                    random_state = 20202020, \n",
    "                    eval_metric = 'auc')\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator = xgb,\n",
    "                               param_grid = params, \n",
    "                               scoring = 'roc_auc',\n",
    "                               n_jobs = -1,\n",
    "                               cv = 3, \n",
    "                               verbose = 0)\n",
    "\n",
    "grid_search_xgb.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7205520555109906"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.45,\n",
       " 'eta': 0.01,\n",
       " 'gamma': 0,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 3,\n",
       " 'subsample': 0.75}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7132918610679108"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = grid_search_xgb.best_estimator_.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC: 71.329 best on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=20202020, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [20], 'max_features': [8],\n",
       "                         'min_samples_leaf': [11], 'min_samples_split': [6],\n",
       "                         'n_estimators': [500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [20],\n",
    "    'max_features': [8],\n",
    "    'min_samples_leaf': [11],\n",
    "    'min_samples_split': [6],\n",
    "    'n_estimators': [500]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 20202020)\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator = rf, \n",
    "                              param_grid = param_grid, \n",
    "                              cv = 3, \n",
    "                              n_jobs = -1, \n",
    "                              verbose = 0, \n",
    "                              scoring = 'roc_auc')\n",
    "\n",
    "grid_search_rf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7149187491334663"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 8,\n",
       " 'min_samples_leaf': 11,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7092565673236635"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = grid_search_rf.best_estimator_.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC: 70.926 best on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found this ensemble method in skLearn, turned out to be better (validation AUC) than stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('gbm', grid_search_gbm.best_estimator_),\n",
    "              ('xgb', grid_search_xgb.best_estimator_),\n",
    "              ('lgbm', lgbm_grid.best_estimator_)]\n",
    "              #('rf', grid_search_rf.best_estimator_)] # validation AUC was better without Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('gbm',\n",
       "                              GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                         criterion='friedman_mse',\n",
       "                                                         init=None,\n",
       "                                                         learning_rate=0.01,\n",
       "                                                         loss='deviance',\n",
       "                                                         max_depth=9,\n",
       "                                                         max_features=0.6,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=10,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         n_estimators=500,\n",
       "                                                         n_iter_no_change=N...\n",
       "                                             learning_rate=0.05, max_depth=-1,\n",
       "                                             metric='auc', min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_data_in_leaf=20,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=500, n_jobs=-1,\n",
       "                                             num_leaves=60, objective='binary',\n",
       "                                             random_state=20202020,\n",
       "                                             reg_alpha=0.0, reg_lambda=0.0,\n",
       "                                             silent=True, subsample=1.0,\n",
       "                                             subsample_for_bin=200000,\n",
       "                                             subsample_freq=0))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclf = VotingClassifier(estimators = estimators, \n",
    "                        voting = 'soft')\n",
    "\n",
    "vclf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To my understanding the 'soft' voting is better here because my base learners are well tuned. This way the VotingClassifier takes the average of the probabilities. Hard voting would use a majority vote and return 1 and 0 classes instead of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713395541731467"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vclf.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC: 71.339 best on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ 'article_id': test['article_id'],\n",
    "                            'score': vclf.predict_proba(X_test)[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"Kr_Rab_Py.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are algos I didn't end up using at all: StackingClassifier and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingClassifier - won't submit, VotingClassifier was better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('gbm', grid_search_gbm.best_estimator_),\n",
    "              #('xgb', grid_search_xgb.best_estimator_),\n",
    "              ('lgbm', lgbm_grid.best_estimator_)]\n",
    "              #('rf', grid_search_rf.best_estimator_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('gbm',\n",
       "                                GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                           criterion='friedman_mse',\n",
       "                                                           init=None,\n",
       "                                                           learning_rate=0.01,\n",
       "                                                           loss='deviance',\n",
       "                                                           max_depth=9,\n",
       "                                                           max_features=0.6,\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           min_impurity_decrease=0.0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=10,\n",
       "                                                           min_samples_split=2,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           n_estimators=500,\n",
       "                                                           n_iter_n...\n",
       "                                               subsample_for_bin=200000,\n",
       "                                               subsample_freq=0))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=100,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=20202020,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='predict_proba',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = StackingClassifier(estimators = estimators, \n",
    "                         final_estimator = LogisticRegression(random_state = 20202020), # logreg is better than gbm\n",
    "                         stack_method = 'predict_proba')\n",
    "\n",
    "clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7124651664709429"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 71.246 best on validation\n",
    "with lgbm and gbm as base learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost (left out of Stack model - takes forever to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 1.23s\tremaining: 10m 13s\n",
      "75:\ttotal: 1m 24s\tremaining: 7m 49s\n",
      "150:\ttotal: 2m 39s\tremaining: 6m 9s\n",
      "225:\ttotal: 3m 55s\tremaining: 4m 45s\n",
      "300:\ttotal: 5m 13s\tremaining: 3m 27s\n",
      "375:\ttotal: 6m 28s\tremaining: 2m 8s\n",
      "450:\ttotal: 7m 50s\tremaining: 51.1s\n",
      "499:\ttotal: 8m 44s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x00000185148F1DD8>,\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bagging_temperature': [0.2], 'border_count': [254],\n",
       "                         'depth': [12], 'l2_leaf_reg': [0],\n",
       "                         'learning_rate': [0.02], 'metric_period': [75],\n",
       "                         'min_data_in_leaf': [10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'border_count': [254],\n",
    "          'l2_leaf_reg': [0],\n",
    "          'depth': [12],\n",
    "          'metric_period': [75],\n",
    "          'bagging_temperature': [0.2], \n",
    "          'learning_rate' : [0.02], \n",
    "          'min_data_in_leaf' : [10]}\n",
    "\n",
    "cbc = CatBoostClassifier(iterations = 500, \n",
    "                         random_seed = 20202020, \n",
    "                         eval_metric = 'AUC')\n",
    "\n",
    "grid_search_cbc = GridSearchCV(estimator = cbc,\n",
    "                               param_grid = params, \n",
    "                               scoring = 'roc_auc',\n",
    "                               n_jobs = -1,\n",
    "                               cv = 3, \n",
    "                               verbose = 0)\n",
    "\n",
    "grid_search_cbc.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6541866034390771"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cbc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_temperature': 0.2,\n",
       " 'border_count': 254,\n",
       " 'depth': 12,\n",
       " 'l2_leaf_reg': 0,\n",
       " 'learning_rate': 0.02,\n",
       " 'metric_period': 75,\n",
       " 'min_data_in_leaf': 10}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.636043842109161"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = grid_search_cbc.best_estimator_.predict_proba(X_val)[:,1]\n",
    "act = y_val.array\n",
    "\n",
    "roc_auc_score(act, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost takes forever and AUC would need huge improvement, so I'm dropping CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
